{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_metadata(wiki_id):\n",
    "#     query = \"\"\"SELECT  ?subject ?subjectLabel\n",
    "#         ?instance ?instanceLabel\n",
    "#         ?subclass ?subclassLabel\n",
    "#         ?inception\n",
    "#         ?time_period ?time_periodLabel\n",
    "#         ?culture ?cultureLabel \n",
    "#         ?architecture_style ?architecture_styleLabel \n",
    "#         ?founded_by ?founded_byLabel \n",
    "#         ?creator ?creatorLabel\n",
    "#         ?country ?countryLabel\n",
    "#         ?territory ?territoryLabel\n",
    "#         ?genre ?genreLabel\n",
    "#         ?movement ?movementLabel\n",
    "#         ?author ?authorLabel\n",
    "#         ?publicationdate\n",
    "#         ?country_origin ?country_originLabel\n",
    "#         ?wikipediaLink\n",
    "# WHERE {\n",
    "#   BIND(wd:%s AS ?subject)\n",
    "#   OPTIONAL { ?subject wdt:P31 ?instance. }\n",
    "#   OPTIONAL { ?subject wdt:P50 ?author. }\n",
    "#   OPTIONAL { ?subject wdt:P279 ?subclass. }\n",
    "#   OPTIONAL { ?subject wdt:P571 ?inception. }\n",
    "#   OPTIONAL { ?subject wdt:P2348 ?time_period. }\n",
    "#   OPTIONAL { ?subject wdt:P2596 ?culture. }\n",
    "#   OPTIONAL { ?subject wdt:P112 ?founded_by. }\n",
    "#   OPTIONAL { ?subject wdt:P170 ?creator. }\n",
    "#   OPTIONAL { ?subject wdt:P17 ?country. }\n",
    "#   OPTIONAL { ?subject wdt:P131 ?territory. }\n",
    "#   OPTIONAL { ?subject wdt:P136 ?genre. }\n",
    "#   OPTIONAL { ?subject wdt:P135 ?movement. }\n",
    "#   OPTIONAL { ?subject wdt:P577 ?publicationdate. }\n",
    "#   OPTIONAL { ?subject wdt:P495 ?country_origin. }\n",
    "  \n",
    "#   OPTIONAL {\n",
    "#     ?wikipediaLink schema:about ?subject;\n",
    "#                   schema:isPartOf <https://en.wikipedia.org/>.\n",
    "#   }\n",
    "  \n",
    "#   SERVICE wikibase:label {\n",
    "#     bd:serviceParam wikibase:language \"en\".\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = []\n",
    "list_df_instance = []\n",
    "list_df_inception = []\n",
    "list_df_subclass = []\n",
    "list_df_genre = []\n",
    "list_df_country = []\n",
    "list_author = []\n",
    "list_df_wikipedia = []\n",
    "list_df_time_period = []\n",
    "list_df_culture = []\n",
    "list_df_publication_date = []\n",
    "list_df_creator = []\n",
    "\n",
    "paths = glob.glob('raw_data/extracts/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:29<00:00,  3.58s/it]\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(paths):\n",
    "\n",
    "    with open(path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    final = []\n",
    "    for x in data:\n",
    "        extracted_values = [{key: value['value'] for key, value in item.items()} for item in x]\n",
    "        final.append(extracted_values)\n",
    "\n",
    "    final_list=[]\n",
    "    for x in final:\n",
    "        res = pd.DataFrame(x)\n",
    "        final_list.append(res)\n",
    "\n",
    "    df = pd.concat([x for x in final_list])\n",
    "    df['subject'] = df['subject'].apply(lambda x: x.split('http://www.wikidata.org/entity/')[1] if isinstance(x, str) and 'entity' in x else None)\n",
    "\n",
    "    df_label = df[[ 'subject', 'subjectLabel']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "    list_df.append(df_label)\n",
    "\n",
    "    try:\n",
    "        df_instance = df[['subject', 'subjectLabel', 'instance', 'instanceLabel']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        df_instance['instance'] = df_instance['instance'].apply(lambda x: x.split('http://www.wikidata.org/entity/')[1] if isinstance(x, str) and 'entity' in x else None)\n",
    "        list_df_instance.append(df_instance)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_inception  = df[['subject', 'subjectLabel', 'inception']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        list_df_inception.append(df_inception)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_subclass = df[['subject', 'subjectLabel', 'subclass', 'subclassLabel']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        df_subclass['subclass'] = df_subclass['subclass'].apply(lambda x: x.split('http://www.wikidata.org/entity/')[1] if isinstance(x, str) and 'entity' in x else None)\n",
    "        list_df_subclass.append(df_subclass)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_genre = df[['subject', 'subjectLabel', 'genre', 'genreLabel']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        df_genre['genre'] = df_genre['genre'].apply(lambda x: x.split('http://www.wikidata.org/entity/')[1] if isinstance(x, str) and 'entity' in x else None)\n",
    "        list_df_genre.append(df_genre)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_country= df[['subject', 'subjectLabel', 'country_origin', 'country_originLabel']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        df_country['country_origin'] = df_country['country_origin'].apply(lambda x: x.split('http://www.wikidata.org/entity/')[1] if isinstance(x, str) and 'entity' in x else None)\n",
    "        list_df_country.append(df_country)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_author= df[['subject', 'subjectLabel', 'author', 'authorLabel']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        df_author['author'] = df_author['author'].apply(lambda x: x.split('http://www.wikidata.org/entity/')[1] if isinstance(x, str) and 'entity' in x else None)\n",
    "        list_author.append(df_author)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_wiki= df[['subject', 'subjectLabel','wikipediaLink']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        list_df_wikipedia.append(df_wiki)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_time_period= df[['subject', 'subjectLabel', 'time_period', 'time_periodLabel']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        df_time_period['time_period'] = df_time_period['time_period'].apply(lambda x: x.split('http://www.wikidata.org/entity/')[1] if isinstance(x, str) and 'entity' in x else None)\n",
    "        list_df_time_period.append(df_time_period)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_culture= df[['subject', 'subjectLabel', 'culture', 'cultureLabel']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        df_culture['culture'] = df_culture['culture'].apply(lambda x: x.split('http://www.wikidata.org/entity/')[1] if isinstance(x, str) and 'entity' in x else None)\n",
    "        list_df_culture.append(df_culture)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_publication_date= df[['subject', 'subjectLabel', 'publicationdate']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        list_df_publication_date.append(df_publication_date)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df_creator= df[['subject', 'subjectLabel', 'creator', 'creatorLabel']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        df_creator['creator'] = df_creator['creator'].apply(lambda x: x.split('http://www.wikidata.org/entity/')[1] if isinstance(x, str) and 'entity' in x else None)\n",
    "        list_df_creator.append(df_creator)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('literay-works.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204064"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([x for x in list_df])\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "final_df.to_sql('objects', conn, if_exists='replace', index=False)\n",
    "\n",
    "final_df_instance = pd.concat([x for x in list_df_instance])\n",
    "final_df_instance = final_df_instance.reset_index(drop=True)\n",
    "final_df_instance.to_sql('instance', conn, if_exists='replace', index=False)\n",
    "\n",
    "final_df_inception = pd.concat([x for x in list_df_inception])\n",
    "final_df_inception = final_df_inception.reset_index(drop=True)\n",
    "final_df_inception.to_sql('inception', conn, if_exists='replace', index=False)\n",
    "\n",
    "# final_df_subclass = pd.concat([x for x in list_df_subclass])\n",
    "# final_df_subclass = final_df_subclass.reset_index(drop=True)\n",
    "# final_df_subclass.to_sql('subclass', conn, if_exists='replace', index=False)\n",
    "\n",
    "final_df_genre = pd.concat([x for x in list_df_genre])\n",
    "final_df_genre = final_df_genre.reset_index(drop=True)\n",
    "final_df_genre.to_sql('genre', conn, if_exists='replace', index=False)\n",
    "\n",
    "final_df_wiki = pd.concat([x for x in list_df_wikipedia])\n",
    "final_df_wiki = final_df_wiki.reset_index(drop=True)\n",
    "final_df_wiki.to_sql('en_wikipedia_link', conn, if_exists='replace', index=False)\n",
    "\n",
    "# final_df_time_period = pd.concat([x for x in list_df_time_period])\n",
    "# final_df_time_period = final_df_time_period.reset_index(drop=True)\n",
    "# final_df_time_period.to_sql('time_period', conn, if_exists='replace', index=False)\n",
    "\n",
    "# final_df_culture = pd.concat([x for x in list_df_culture])\n",
    "# final_df_culture = final_df_culture.reset_index(drop=True)\n",
    "# final_df_culture.to_sql('culture', conn, if_exists='replace', index=False)\n",
    "\n",
    "final_df_publication_date = pd.concat([x for x in list_df_publication_date])\n",
    "final_df_publication_date = final_df_publication_date.reset_index(drop=True)\n",
    "final_df_publication_date.to_sql('publication_date', conn, if_exists='replace', index=False)\n",
    "\n",
    "# final_df_creator = pd.concat([x for x in list_df_creator])\n",
    "# final_df_creator = final_df_creator.reset_index(drop=True)\n",
    "# final_df_creator.to_sql('creator', conn, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "final_df_country = pd.concat([x for x in list_df_country])\n",
    "final_df_country = final_df_country.reset_index(drop=True)\n",
    "final_df_country.to_sql('country', conn, if_exists='replace', index=False)\n",
    "\n",
    "final_df_author = pd.concat([x for x in list_author])\n",
    "final_df_author = final_df_author.reset_index(drop=True)\n",
    "final_df_author.to_sql('author', conn, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
